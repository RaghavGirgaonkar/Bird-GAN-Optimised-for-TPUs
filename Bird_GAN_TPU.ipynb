{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "wxnWkD8ZFi5x"
      },
      "outputs": [],
      "source": [
        "#@title Import libraries { form-width: \"20%\" }\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from IPython import display\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from math import ceil\n",
        "import cv2\n",
        "from tensorflow.python.ops.numpy_ops import np_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re1BLdQFIxp5",
        "outputId": "6bf3c437-e8eb-41e1-c325-811c15ded2bd"
      },
      "outputs": [],
      "source": [
        "#@title Install packages to generate GIFs { form-width: \"20%\" }\n",
        "# To generate GIFs\n",
        "!pip install imageio\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec1RH7BZqwCo",
        "outputId": "a4670058-1fa6-4ec6-e0a6-2544436061b4"
      },
      "outputs": [],
      "source": [
        "#@title TPU initialization { form-width: \"20%\" }\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyNmZBSptb5C",
        "outputId": "dac64658-d720-438f-bbc9-eff090d36ca4"
      },
      "outputs": [],
      "source": [
        "#@title Mount Google Drive { form-width: \"20%\" }\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzyyma5fa4jY",
        "outputId": "b5c3c815-b7fd-424d-cfa3-5027d885f5b1"
      },
      "outputs": [],
      "source": [
        "#@title Unzip dataset { form-width: \"20%\" }\n",
        "!unzip /content/drive/MyDrive/archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0yFIT4_NRFOj"
      },
      "outputs": [],
      "source": [
        "#@title Functions to read, write and upload tfrecord files { form-width: \"20%\" }\n",
        "def _int_feature(list_of_ints): # int64\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n",
        "def _float_feature(list_of_floats): # float32\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n",
        "def _bytestring_feature(list_of_bytestrings):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n",
        "  \n",
        "def write_tfrecord_file(path, image_paths):\n",
        "    with tf.io.TFRecordWriter(path) as writer:\n",
        "        for index in tqdm(range(len(image_paths))):\n",
        "            with open(image_paths[index], 'rb') as fp:\n",
        "                img = fp.read()\n",
        "\n",
        "            feature = {\n",
        "                \"image\": _bytestring_feature([img]),\n",
        "            }\n",
        "            tf_record = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "            writer.write(tf_record.SerializeToString())\n",
        "\n",
        "def upload_tfrecord_file_to_gcs(bucket, path):\n",
        "    !gsutil cp {path} gs://{bucket}/\n",
        "\n",
        "def read_tfrecord(data):\n",
        "    features = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "    }\n",
        "    tf_record = tf.io.parse_single_example(data, features)\n",
        "    image = tf.io.decode_jpeg(tf_record['image'], channels=3)\n",
        "    image = tf.image.resize(image, [128,128], antialias=True, method = 'nearest')\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gda5CfYMM24",
        "outputId": "10b0505f-b261-47eb-c708-bd428782dc32"
      },
      "outputs": [],
      "source": [
        "#@title Write and upload tfrecord dataset { form-width: \"20%\" }\n",
        "data_path = '/content/train/'\n",
        "image_paths = []\n",
        "for root, subdirs, files in os.walk(data_path):\n",
        "    for f in files:\n",
        "        image_paths += [os.path.join(root, f)]\n",
        "\n",
        "project_id = 'bird-gan'\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "!gcloud config set project {project_id}\n",
        "\n",
        "bucket_name = 'bird_gan_data'\n",
        "output_file_path = '/content/image_dataset.tfrecords'\n",
        "num_files = 1\n",
        "num_shards = 1\n",
        "dataset_size = int(len(image_paths)/num_shards)\n",
        "print(dataset_size)\n",
        "\n",
        "write_tfrecord_file(output_file_path, image_paths)\n",
        "upload_tfrecord_file_to_gcs(bucket_name, output_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UwpNjfEfPfo7"
      },
      "outputs": [],
      "source": [
        "#@title Create dataset { form-width: \"20%\" } { form-width: \"20%\" }\n",
        "def get_dataset(per_replica_batch_size, normalize):\n",
        "    gs_paths = ['gs://bird_gan_data/image_dataset.tfrecords']\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset([gs_paths])\n",
        "    dataset = dataset.with_options(ignore_order)  \n",
        "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
        "    # dataset = dataset.shard(num_shards, 0)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.shuffle(dataset_size, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "    dataset = dataset.batch(per_replica_batch_size)\n",
        "\n",
        "    if normalize:\n",
        "        dataset = dataset.map(lambda x: x / 255)\n",
        "        dataset = dataset.map(lambda x: x*2 - 1)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "tKqndKrAWMw5",
        "outputId": "ab51a6e8-203f-4609-967e-9b0b498e9939"
      },
      "outputs": [],
      "source": [
        "#@title Display dataset { form-width: \"20%\" }\n",
        "dataset_demo = get_dataset(16, False)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images in dataset_demo.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i+1)\n",
        "        plt.imshow(images[i].numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GJ-s1k6Daxda"
      },
      "outputs": [],
      "source": [
        "#@title Define generator model { form-width: \"20%\" }\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(layers.Dense(4*4*256, input_shape = (256,)))\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.Reshape((4,4,256)))\n",
        "    assert model.output_shape == (None, 4, 4, 256)\n",
        "\n",
        "    model.add(layers.UpSampling2D())\n",
        "    model.add(layers.Conv2D(256, kernel_size = 3, padding = 'same'))\n",
        "    model.add(layers.BatchNormalization(momentum = 0.8))\n",
        "    model.add(layers.Activation('relu'))\n",
        "    # shape = (None, 8, 8, 256)\n",
        "\n",
        "    model.add(layers.UpSampling2D()) \n",
        "    model.add(layers.Conv2D(256, kernel_size = 3, padding = 'same'))\n",
        "    model.add(layers.BatchNormalization(momentum = 0.8))\n",
        "    model.add(layers.Activation('relu'))\n",
        "    # shape = (None, 16, 16, 256)\n",
        "\n",
        "    model.add(layers.UpSampling2D()) \n",
        "    model.add(layers.Conv2D(128, kernel_size = 3, padding = 'same'))\n",
        "    model.add(layers.BatchNormalization(momentum = 0.8))\n",
        "    model.add(layers.Activation('relu'))\n",
        "    # shape = (None, 32, 32, 128)\n",
        "\n",
        "    model.add(layers.UpSampling2D())\n",
        "    model.add(layers.Conv2D(128, kernel_size = 3, padding = 'same'))\n",
        "    model.add(layers.BatchNormalization(momentum = 0.8))\n",
        "    model.add(layers.Activation('relu'))\n",
        "    # shape = (None, 64, 64, 128)\n",
        "\n",
        "    model.add(layers.UpSampling2D())\n",
        "    model.add(layers.Conv2D(128, kernel_size = 3, padding = 'same'))\n",
        "    model.add(layers.BatchNormalization(momentum = 0.8))\n",
        "    model.add(layers.Activation('relu'))\n",
        "    # shape = (None, 128, 128, 128)\n",
        "\n",
        "    model.add(layers.Conv2D(3,kernel_size = 3, padding = 'same'))\n",
        "    assert model.output_shape == (None, 128, 128, 3)\n",
        "    model.add(layers.Activation('tanh'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZLZMtPS9Wpp8"
      },
      "outputs": [],
      "source": [
        "#@title Define discriminator model { form-width: \"20%\" }\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    model.add(layers.GaussianNoise(0.1))\n",
        "    model.add(layers.Conv2D(32, kernel_size = 3, strides = 2, input_shape = [128,128,3], padding = 'same'))\n",
        "    model.add(layers.LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.GaussianNoise(0.1))\n",
        "    model.add(layers.Conv2D(64, kernel_size = 3, strides = 2, padding = 'same'))\n",
        "    model.add(layers.ZeroPadding2D(padding = ((0,1), (0,1))))\n",
        "    model.add(layers.BatchNormalization(momentum = 0.8))\n",
        "    model.add(layers.LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.GaussianNoise(0.1))\n",
        "    model.add(layers.Conv2D(128, kernel_size = 3, strides = 2, padding = 'same'))\n",
        "    model.add(layers.BatchNormalization(momentum = 0.8))\n",
        "    model.add(layers.LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.GaussianNoise(0.1))\n",
        "    model.add(layers.Conv2D(256, kernel_size = 3, strides = 1, padding = 'same'))\n",
        "    model.add(layers.BatchNormalization(momentum = 0.8))\n",
        "    model.add(layers.LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.GaussianNoise(0.1))\n",
        "    model.add(layers.Conv2D(512, kernel_size = 3, strides = 1, padding = 'same'))\n",
        "    model.add(layers.BatchNormalization(momentum = 0.8))\n",
        "    model.add(layers.LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.GaussianNoise(0.1))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl7BaGi9XHXR"
      },
      "outputs": [],
      "source": [
        "#@title Loss and optimiser { form-width: \"20%\" }\n",
        "with strategy.scope():\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "    def discriminator_loss(real_output, fake_output):\n",
        "        # real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "        # fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "        real_loss = cross_entropy(tf.random.uniform((32,1), minval=0.9, maxval=1), real_output)\n",
        "        fake_loss = cross_entropy(tf.random.uniform((32,1), minval=0, maxval=0.1), fake_output)\n",
        "        total_loss = real_loss + fake_loss\n",
        "        return total_loss\n",
        "\n",
        "    def generator_loss(fake_output):\n",
        "        return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfZIrpBMXi0n"
      },
      "outputs": [],
      "source": [
        "G_lr = 0.0002\n",
        "D_lr = 0.0002\n",
        "with strategy.scope():\n",
        "    generator_optimizer = tf.keras.optimizers.Adam(G_lr)\n",
        "    discriminator_optimizer = tf.keras.optimizers.Adam(D_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVPd9gSgXDhJ"
      },
      "outputs": [],
      "source": [
        "#@title Create model objects { form-width: \"20%\" }\n",
        "with strategy.scope():\n",
        "    generator = make_generator_model()\n",
        "    discriminator = make_discriminator_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oX_JwjTMXkj5"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "with strategy.scope():\n",
        "    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                    discriminator_optimizer=discriminator_optimizer,\n",
        "                                    generator=generator,\n",
        "                                    discriminator=discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbGX-GrfXnTD"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 1000\n",
        "batch_size = 256\n",
        "noise_dim = 256\n",
        "num_examples_to_generate = 16\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlJgWx8HXvUo",
        "outputId": "3c093dfc-0cf3-41c0-af5c-07d00aec1dd4"
      },
      "outputs": [],
      "source": [
        "#@title Define training step { form-width: \"20%\" }\n",
        "per_replica_batch_size = batch_size // strategy.num_replicas_in_sync # Each worker in the TPU will train on this batch size\n",
        "print(per_replica_batch_size)\n",
        "\n",
        "train_dataset = strategy.distribute_datasets_from_function(\n",
        "    lambda _: get_dataset(per_replica_batch_size, True))\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator, steps): \n",
        "    def step_fn(images): # This function is distributed across the workers of the TPU\n",
        "        noise = tf.random.normal([per_replica_batch_size, noise_dim])\n",
        "\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            generated_images = generator(noise, training=True)\n",
        "\n",
        "            real_output = discriminator(images, training=True)\n",
        "            fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "            gen_loss = generator_loss(fake_output)\n",
        "            disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    for _ in tf.range(steps):\n",
        "        strategy.run(step_fn, args=(next(iterator),)) # steps_per_epoch number of steps are run in one call of training_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gg_e-IVGX4vh"
      },
      "outputs": [],
      "source": [
        "#@title Define training loop { form-width: \"20%\" }\n",
        "def train_TPU(train_dataset, EPOCHS):\n",
        "    steps_per_epoch = (dataset_size // batch_size)\n",
        "    print(steps_per_epoch)\n",
        "    train_iterator = iter(train_dataset)\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        start = time.time()\n",
        "        print(f'Epoch: {epoch+1}/{EPOCHS}')\n",
        "\n",
        "        train_step(train_iterator, tf.convert_to_tensor(steps_per_epoch))\n",
        "\n",
        "        # Produce images for the GIF as you go\n",
        "        display.clear_output(wait=True)\n",
        "        generate_and_save_images(generator,\n",
        "                                epoch + 1,\n",
        "                                seed)\n",
        "        \n",
        "        # Save the model every 15 epochs\n",
        "        # if (epoch + 1) % 15 == 0:\n",
        "        # checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "        \n",
        "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "    \n",
        "    # Generate after the final epoch\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                            EPOCHS,\n",
        "                            seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMhfbeqlX8Wq"
      },
      "outputs": [],
      "source": [
        "#@title Define function to display generator outputs { form-width: \"20%\" }\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    with strategy.scope():\n",
        "        predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 12))\n",
        "    \n",
        "    np_config.enable_numpy_behavior()\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow((predictions[i]*127.5 + 127.5).astype(np.uint8))\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "Lu-r0FfcYAz0",
        "outputId": "5c56ed7d-4c35-465d-95f4-7df1704b9bb7"
      },
      "outputs": [],
      "source": [
        "train_TPU(train_dataset, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxsCrXN5rfYe"
      },
      "outputs": [],
      "source": [
        "#@title Display a single image using the epoch number { form-width: \"20%\" }\n",
        "def display_image(epoch_no):\n",
        "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YheZXUelrl9B"
      },
      "outputs": [],
      "source": [
        "display_image(697)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFwR4YngrohZ"
      },
      "outputs": [],
      "source": [
        "#@title Create GIF of training progress { form-width: \"20%\" }\n",
        "anim_file = 'bird_dcgan.mp4'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "    filenames = glob.glob('image*.png')\n",
        "    filenames = sorted(filenames)\n",
        "    for filename in filenames:\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qJlEkPBWnVO"
      },
      "outputs": [],
      "source": [
        "#@title Save model { form-width: \"20%\" }\n",
        "checkpoint.save(file_prefix = '/content/drive/')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Bird-GAN-TPU.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
